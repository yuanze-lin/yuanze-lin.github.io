<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yuanze Lin</title>

    <meta name="author" content="Yuanze Lin">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yuanze Lin
                </p>
                <p>I am a Computer Science DPhil student at <a href="https://www.ox.ac.uk/">University of Oxford</a>, advised by <a href="https://scholar.google.com/citations?hl=en&user=0bzqo0YAAAAJ">Ronald Clark</a> and <a href="https://scholar.google.com/citations?hl=en&user=185g9ckAAAAJ">Niki Trigoni</a>, my research interests include self-supervised learning, multimodal learning and large language models.
                <p>
                  Before going to Oxford, I've done research at <a href="https://www.microsoft.com/en-us/research/project/project-florence-vl/publications/">Microsoft Redmond</a>, <a href="https://www.msra.cn/">MSRA</a>, <a href="https://www.jhu.edu/">Johns Hopkins University</a>, <a href="https://www.tsinghua.edu.cn/en/"> Tsinghua University</a>, etc. I'm so lucky to work with <a href="https://www.microsoft.com/en-us/research/people/xunguo/"> Xun Guo</a> and 
                  <a href="https://www.microsoft.com/en-us/research/people/yanlu/"> Yan Lu</a> at MSRA,  <a href="http://www.gaohuang.net/"> Gao Huang</a> at Tsinghua University, <a href="https://sites.google.com/view/yujia"> Yujia Xie</a>, <a href="https://www.dongdongchen.bid/"> Dongdong Chen</a> and <a href="https://xycking.wixsite.com/yichongxu">Yichong Xu</a> at Microsoft Redmond, <a href="https://cihangxie.github.io/"> Cihang Xie</a> and <a href="https://www.cs.jhu.edu/~ayuille/"> Alan Yuille</a> at Johns Hopkins University.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yuanze.lin@cs.ox.ac.uk">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=0WFC2w0AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://openreview.net/profile?id=~Yuanze_Lin1">OpenReview</a> &nbsp;/&nbsp;
                  <a href="https://github.com/yuanze-lin/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/yuanze-lin-720543139/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/yuanze.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yuanze_circle.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm particularly interested in computer vision, especially about how to efficiently utilize images and texts for pre-training or solving various multimodal tasks.  Selected papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
    
      <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/zipnerf.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/zipnerf.jpg' width="160">
          </div>
          <script type="text/javascript">
            function zipnerf_start() {
              document.getElementById('zipnerf_image').style.opacity = "1";
            }

            function zipnerf_stop() {
              document.getElementById('zipnerf_image').style.opacity = "0";
            }
            zipnerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2211.11446">
            <span class="papertitle">SMAUG: Sparse Masked Autoencoder for Efficient Video-Language Pre-training</span>
          </a>
          <br>
          <strong>Yuanze Lin</strong>,
          <a href="https://weichen582.github.io/">Chen Wei</a>,
          <a href="https://csrhddlam.github.io/">Huiyu Wang</a>,
          <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>,
          <a href="https://cihangxie.github.io/">Cihang Xie</a>,
          <br>
          <em>ICCV</em>, 2023 
          <br>
          <a href="https://arxiv.org/pdf/2211.11446">arXiv</a>
          /
          <a href="https://arxiv.org/pdf/2211.11446">poster</a>
          /
          <a href="https://arxiv.org/pdf/2211.11446">video</a>
          <p></p>
          <p>
          Propose an efficient multimodal pre-training framework, which enjoys both competitive performances on text-to-video retrieval and video question answering tasks, and much less pre-training costs by 1.9X or more.
          </p>
        </td>
      </tr>
      
      
      <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='db3d_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/owl.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/owl.png' width="160">
          </div>
          <script type="text/javascript">
            function db3d_start() {
              document.getElementById('db3d_image').style.opacity = "1";
            }

            function db3d_stop() {
              document.getElementById('db3d_image').style.opacity = "0";
            }
            db3d_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/44956951349095f74492a5471128a7e0-Paper-Conference.pdf">
            <span class="papertitle">REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering</span>
          </a>
          <br>
  <strong>Yuanze Lin</strong>, <a href="https://sites.google.com/view/yujia">Yujia Xie</a>, <a href="https://www.dongdongchen.bid/">Dongdong Chen</a>, <a href="https://xycking.wixsite.com/yichongxu">Yichong Xu</a>, <a href="https://scholar.google.com/citations?user=1b2kKWoAAAAJ&hl=zh-CN">Chenguang Zhu</a>, 
  <a href="https://scholar.google.com/citations?user=k9TsUVsAAAAJ&hl=zh-CN">Lu Yuan</a>, 
          
          <br>
          <em>NeurIPS</em>, 2022
          <br>
          <a href="https://arxiv.org/abs/2206.01201">arXiv</a> / 
          <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202022/0bf727e907c5fc9d5356f11e4c45d613.png?t=1667706317.0158653">poster</a> /
          <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/44956951349095f74492a5471128a7e0-Supplemental-Conference.pdf">supplementary material</a> /
          <a href="https://openreview.net/forum?id=wwyiEyK-G5D">openreview</a> /
          <a href="https://github.com/yuanze-lin/REVIVE">code</a> 
          <p></p>
          <p>propose a new knowledge-based VQA method REVIVE, which tries to utilize the explicit information of object regions not only in the knowledge retrieval stage but also in the answering model. We perform extensive experiments on the standard OK-VQA dataset and achieve new state-of-the-art performance, i.e., 58.0% accuracy, surpassing previous state-of-the-art method by a large margin (+3.6%).</p>
        </td>
      </tr>

      

      <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/bakedsdf_after.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/bakedsdf_before.jpg' width="160">
          </div>
          <script type="text/javascript">
            function bakedsdf_start() {
              document.getElementById('bakedsdf_image').style.opacity = "1";
            }

            function bakedsdf_stop() {
              document.getElementById('bakedsdf_image').style.opacity = "0";
            }
            bakedsdf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Pseudo-Q_Generating_Pseudo_Language_Queries_for_Visual_Grounding_CVPR_2022_paper.pdf">
            <span class="papertitle">Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding</span>
          </a>
          <br>
          <a href="https://github.com/jianghaojun">Haojun Jiang*</a>,
          <strong>Yuanze Lin*</strong>,
          <a href="https://scholar.google.com/citations?user=wv3U3tkAAAAJ&hl=en">Dongchen Han,</a>,
          <a href="https://scholar.google.com/citations?user=rw6vWdcAAAAJ&hl=zh-CN">Shiji Song</a>,  
          <a href="http://www.gaohuang.net/">Gao Huang</a>, 
          <br>
          <em>CVPR</em>, 2022
          <br>
          <a href="https://arxiv.org/abs/2203.08481">arXiv</a> /
          <a href="https://cloud.tsinghua.edu.cn/f/e5f6df930e5d4b21ae27/">poster</a> /
          <a href="https://cloud.tsinghua.edu.cn/f/d655d6e2a6b246b4bb4f/">video</a> /
          <a href="https://github.com/LeapLabTHU/Pseudo-Q">code</a> 
          <p></p>
          <p>
          Present a novel method, named Pseudo-Q, to automatically generate pseudo language queries for supervised training, t achieves superior or comparable performance compared to state-of-the-art weakly-supervised visual grounding methods on all the five datasets we have experimented.
          </p>
        </td>
      </tr>



          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
          <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
